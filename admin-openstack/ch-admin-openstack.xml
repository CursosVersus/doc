<?xml version="1.0" encoding="utf-8"?>
<chapter xmlns="http://docbook.org/ns/docbook"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0"
         xml:id="ch-admin-openstack">
  <title>Administración de OpenStack</title>

  <para>Aunque gran parte de tareas de administración de OpenStack se pueden realizar
  de forma intuitiva desde la interfaz gráfica web Horizon(dashboard), aquí se presentan los comandos más usados para la administración desde la consola</para>
 
  <section>
    <title>Gestión de instancias</title>
    
    <para>Una vez que se tenga alguna imagen dada de alta en nuestro sistema se
    podrán arrancar instancias de ésta. Estas instancias se ejecutarán en el o
    los nodos de computación que estén activos.</para>

    <para>Podemos listar las imágenes que tengamos en glance:</para>

    <screen><prompt>$ </prompt><userinput>glance index</userinput></screen>

    <screen>
root@neo:~# glance index
ID                                   Name                           Disk Format
Container Format     Size          
------------------------------------ ------------------------------
-------------------- -------------------- --------------
86119171-9ed6-435c-9620-573e0b440e58 Windows 7 general              vdi
bare                    14463094784
2710174c-9388-4d55-8ece-ace0250817de Ubuntu 12.04 Server            qcow2
bare                      233177088
838d547b-4a6c-4177-9e6a-fb6695b67cd4 Cirros (test) 0.3.0 64 bits    qcow2
bare                        9761280
root@neo:~#
    </screen>
    
    <para>Como vemos tenemos actualmente tres imágenes disponibles para ser
    instanciadas. Una imagen de Windows 7 en formato vdi (Virtualbox) y dos
    imagenes en qcow2, una de Ubuntu 12.04 Server y otra Cirros.</para>

    <para>Para instanciar una de las imágenes es necesario saber qué plantillas
    de ejecución (flavor) tenemos disponibles en nuestro sistema.</para>

    <para>Si no las conocemos, listamos las plantillas disponibles en nuestro sistema:</para>
    
    <screen><prompt>$ </prompt><userinput>nova manage flavor list</userinput></screen>

    <screen>
m1.medium: Memory: 4096MB, VCPUS: 2, Root: 40GB, Ephemeral: 0Gb, FlavorID: 3,
Swap: 0MB, RXTX Factor: 1.0
m1.large: Memory: 8192MB, VCPUS: 4, Root: 80GB, Ephemeral: 0Gb, FlavorID: 4,
Swap: 0MB, RXTX Factor: 1.0
m1.tiny: Memory: 512MB, VCPUS: 1, Root: 0GB, Ephemeral: 0Gb, FlavorID: 1, Swap:
0MB, RXTX Factor: 1.0
m1.xlarge: Memory: 16384MB, VCPUS: 8, Root: 160GB, Ephemeral: 0Gb, FlavorID: 5,
Swap: 0MB, RXTX Factor: 1.0
m1.small: Memory: 2048MB, VCPUS: 1, Root: 20GB, Ephemeral: 0Gb, FlavorID: 2,
Swap: 0MB, RXTX Factor: 1.0
    </screen>

    <para>Vemos que por defecto el sistema viene con 5 plantillas de
    ejecución</para>

    <para>En nuestro ejemplo vamos a instanciar la imagen de Ubuntu con la plantilla
    <emphasis>m1.small</emphasis></para>

    <screen><prompt>$ </prompt><userinput>nova boot --image "Ubuntu 12.04 Server" --flavor m1.small ubuntuserver1</userinput></screen>

    <screen>
+-------------------------------------+--------------------------------------+
|               Property              |                Value                 |
+-------------------------------------+--------------------------------------+
| OS-DCF:diskConfig                   | MANUAL                               |
| OS-EXT-SRV-ATTR:host                | None                                 |
| OS-EXT-SRV-ATTR:hypervisor_hostname | None                                 |
| OS-EXT-SRV-ATTR:instance_name       | instance-00000035                    |
| OS-EXT-STS:power_state              | 0                                    |
| OS-EXT-STS:task_state               | scheduling                           |
| OS-EXT-STS:vm_state                 | building                             |
| accessIPv4                          |                                      |
| accessIPv6                          |                                      |
| adminPass                           | hvpgLFGuF9ne                         |
| config_drive                        |                                      |
| created                             | 2012-09-19T12:07:42Z                 |
| flavor                              | m1.small                             |
| hostId                              |                                      |
| id                                  | f7cb19ef-06a4-433e-806c-ab0db55e30a2 |
| image                               | Ubuntu 12.04 Server                  |
| key_name                            |                                      |
| metadata                            | {}                                   |
| name                                | ubuntuserver1                        |
| progress                            | 0                                    |
| status                              | BUILD                                |
| tenant_id                           | a70373bf297a42eb9203645d84476c23     |
| updated                             | 2012-09-19T12:07:42Z                 |
| user_id                             | 4c249654613e41208b2d03169ef29580     |
+-------------------------------------+--------------------------------------+
    </screen>


    <para>Podemos ver que el sistema nos ha devuelto todos los datos de la instancia que se
    está construyendo.</para>

    <para>Seguidamente se puede listar en qué estado está nuestras instancias con:</para>

    <screen><prompt>$ </prompt><userinput>nova list</userinput></screen>

    <screen>
+--------------------------------------+---------------+--------+------------------+
|                  ID                  |      Name     | Status |     Networks
|
+--------------------------------------+---------------+--------+------------------+
| f7cb19ef-06a4-433e-806c-ab0db55e30a2 | ubuntuserver1 | BUILD  | private=10.0.0.2 |
+--------------------------------------+---------------+--------+------------------+
    </screen>

    <para>Como vemos la instancia está aún construyéndose</para>

    <para>Si todo ha ido bien al cabo de un tiempo deberá aparecer la instancia como
    activa</para>

    <screen><prompt>$ </prompt><userinput>nova list</userinput>
+--------------------------------------+---------------+--------+------------------+
|                  ID                  |      Name     | Status |     Networks
|
+--------------------------------------+---------------+--------+------------------+
| f7cb19ef-06a4-433e-806c-ab0db55e30a2 | ubuntuserver1 | ACTIVE | private=10.0.0.2 |
+--------------------------------------+---------------+--------+------------------+
    </screen>

    <para>Una vez creadas varias instancias podemos ver su estado:</para>

    <screen><prompt>$ </prompt><userinput>nova list</userinput></screen>
    <screen>
+--------------------------------------+---------------+--------+------------------+
|                  ID                  |      Name     | Status |     Networks
|
+--------------------------------------+---------------+--------+------------------+
| 9273c28b-7db9-41aa-916a-b4589420af58 | ubuntuserver4 | ACTIVE |
private=10.0.0.5 |
| cd5e6c35-9e62-49d7-815f-c3ea09540806 | ubuntuserver2 | ACTIVE |
private=10.0.0.3 |
| dbefde80-48e1-48b0-a8b0-84f2ddc7a1f7 | ubuntuserver3 | ACTIVE |
private=10.0.0.4 |
| f7cb19ef-06a4-433e-806c-ab0db55e30a2 | ubuntuserver1 | ACTIVE |
private=10.0.0.2 |
+--------------------------------------+---------------+--------+------------------+
    </screen>

    <para>Las demás acciones que se pueden realizar con una instancia se listan
    a continuación:</para>
    <itemizedlist>
      <listitem>
	<para><emphasis role="bold">Lanzar instancia en un nodo:</emphasis>si
	se desea lanzar una instancia en un nodo en concreto se tiene que forzar
	con los flags <emphasis>--hint force_hosts=</emphasis></para>
	<screen><prompt>$ </prompt><userinput>nova boot --image "Ubuntu 12.04 Server" --flavor m1.small --hint force_hosts=trinity ubuntuserver5</userinput></screen>

<screen>
+-------------------------------------+----------------------------------------------------------+
|               Property              |                          Value
|
+-------------------------------------+----------------------------------------------------------+
| OS-DCF:diskConfig                   | MANUAL
|
| OS-EXT-SRV-ATTR:host                | trinity
|
| OS-EXT-SRV-ATTR:hypervisor_hostname | None
|
| OS-EXT-SRV-ATTR:instance_name       | instance-0000003c
|
| OS-EXT-STS:power_state              | 1
|
| OS-EXT-STS:task_state               | None
|
| OS-EXT-STS:vm_state                 | active
|
| accessIPv4                          |
|
| accessIPv6                          |
|
| config_drive                        |
|
| created                             | 2012-09-19T18:30:48Z
|
| flavor                              | m1.small
|
| hostId                              |
c4cfd12e74d001411d189ab076248cd268b2b7cfda5017cf67376682 |
| id                                  | d21be20f-3a03-4979-8d5c-6a32dab71a43
|
| image                               | Ubuntu 12.04 Server
|
| key_name                            |
|
| metadata                            | {}
|
| name                                | ubuntuserver5
|
| private network                     | 10.0.0.6
|
| progress                            | 0
|
| status                              | ACTIVE
|
| tenant_id                           | a70373bf297a42eb9203645d84476c23
|
| updated                             | 2012-09-19T18:30:29Z
|
| user_id                             | 4c249654613e41208b2d03169ef29580
|
+-------------------------------------+----------------------------------------------------------+
	</screen>
	<note><para>Atención la funcionalidad de forzar nodo de computación solo funciona con ciertos tipos
	de planificadores (scheduler). No funciona
	con<emphasis>SimpleScheduler</emphasis> pero si con <emphasis>Filter Scheduler</emphasis></para></note> 

      </listitem>
      <listitem>
	<para><emphasis role="bold">Pausar instancia:</emphasis></para>
	<screen><prompt>$ </prompt><userinput> nova pause $id_de_instancia</userinput></screen>
      </listitem>
      <listitem>
        <para><emphasis role="bold">Reanudar instancia pausada:</emphasis></para>                                              
        <screen><prompt>$ </prompt><userinput> nova unpause $id_de_instancia</userinput></screen>
      </listitem>
      <listitem>
        <para><emphasis role="bold">Suspender una instancia:</emphasis></para>
        <screen><prompt>$ </prompt><userinput> nova suspend $id_de_instancia</userinput></screen>
      </listitem>
      <listitem>
        <para><emphasis role="bold">Reanudar una instancia suspendida:</emphasis></para>
        <screen><prompt>$ </prompt><userinput> nova resume $id_de_instancia</userinput></screen>
      </listitem>
      <listitem>
        <para><emphasis role="bold">Borrar una instancia (debe estar activa):</emphasis></para>
        <screen><prompt>$ </prompt><userinput> nova delete $id_de_instancia</userinput></screen>
      </listitem>
    </itemizedlist>
</section>

<section xml:id="id_admin_plantillas">
  <title>Gestión de plantillas</title>
  <para>Las plantillas o flavors describen la CPU, memoria y tamaño de
  almacenamiento que van a poder ocupar las distintas instancias en nova.</para>
  <para>Así cada instancia va a poder ocupar el máximo de estos recursos una
  vez levantada.</para>
  <para>En nova se van a poder utilizar las plantillas que vienen por defecto y
  también se pueden crear nuevas plantillas en caso de que sea necesario.</para>
  <para>Las siguientes acciones se pueden realizar con las plantillas:</para>
  <itemizedlist>
    <listitem>
      <para><emphasis role="bold">Listar las distintas plantillas
      existentes:</emphasis></para>
      <screen><prompt>$</prompt><userinput>nova-manage flavor list</userinput></screen>
      <screen>
m1.medium: Memory: 4096MB, VCPUS: 2, Root: 10GB, Ephemeral: 40Gb, FlavorID: 3, Swap: 0MB, RXTX Factor: 1.0
m1.asir: Memory: 256MB, VCPUS: 1, Root: 5GB, Ephemeral: 0Gb, FlavorID: 6, Swap: 0MB, RXTX Factor: 1.0
m1.small: Memory: 2048MB, VCPUS: 1, Root: 10GB, Ephemeral: 20Gb, FlavorID: 2, Swap: 0MB, RXTX Factor: 1.0
m1.large: Memory: 8192MB, VCPUS: 4, Root: 10GB, Ephemeral: 80Gb, FlavorID: 4,Swap: 0MB, RXTX Factor: 1.0
m1.tiny: Memory: 512MB, VCPUS: 1, Root: 0GB, Ephemeral: 0Gb, FlavorID: 1, Swap: 0MB, RXTX Factor: 1.0
m1.xlarge: Memory: 16384MB, VCPUS: 8, Root: 10GB, Ephemeral: 160Gb, FlavorID: 5 Swap: 0MB, RXTX Factor: 1.0
      </screen>
    </listitem>
    <listitem>
    <para><emphasis role="bold">Crear una nueva plantilla</emphasis></para>
    <screen><prompt>$</prompt><userinput>nova-manage flavor create --name=m1.xxlarge
    --memory=16384 --cpu=16 --local_gb=20 --flavor=7 --swap=0 --rxtx_quota=0
    --rxtxcap=0
	</userinput>
    </screen>
    </listitem>
    <listitem>
      <para><emphasis role="bold">Borrar una plantilla
      existente</emphasis></para>
      <screen><prompt>$</prompt><userinput>nova-manage flavor delete --name=m1.xxlarge</userinput></screen>
    </listitem>
  </itemizedlist>
</section>


<section xml:id="id_admin_usuarios">
  <title>Gestión de usuarios</title>
  <para>La gestión de usuarios para esta versión de Openstack se puede realizar
  de forma ágil desde la interfaz gráfica de Horizon. Sin embargo si se desea
  utilizar la interfaz de comandos deberemos utilizar <emphasis
  role="bold">keystone</emphasis> para la creación y administración de
  usuarios.</para>

  <para>Atención: en versiones anteriores se podía crear usuarios a través de
  <emphasis role="bold">nova-manage</emphasis>, método a extinguir desde que
  existe keystone. 
  </para>

  <itemizedlist>
  <listitem>
    <para>Listar los usuarios existentes</para>
    <screen><prompt>$</prompt><userinput>keystone user-list</userinput></screen>
    <screen>
+----------------------------------+---------+--------------------+--------+
|                id                | enabled |       email        |  name  |
+----------------------------------+---------+--------------------+--------+
| 05743001bbf14700bcdf2ecc43edbf9b | True    | alex@iescierva.net | admin  |
| 246ba4e3d81c4ae8bdde8ec5784e74d3 | True    | alex@iescierva.net | swift  |
| 291c58f7258747758d109ecee2eb4a69 | True    | alex@iescierva.net | glance |
| 404dafc53b364a7e9f1476aa98082966 | True    | alex@iescierva.net | nova   |
+----------------------------------+---------+--------------------+--------+
    </screen>
  </listitem>
  <listitem>
  <para>Crear un usuario nuevo asociado a un proyecto (sabiendo el id de proyecto-tenant)</para>
<screen><prompt>$</prompt><userinput> keystone user-create --name alumno
--tenant_id e7b1868b24a742318f1d73f612ecfe1d --pass curso12-13 --email correo@gmail.com 
</userinput></screen>

<screen>
+----------+-------------------------------------------------------------------------------------------------------------------------+
| Property |                                                          Value
|
+----------+-------------------------------------------------------------------------------------------------------------------------+
| email    | correo@gmail.com
|
| enabled  | True
|
| id       | d0bfed18cce3460892ae99ee812d8aa3
|
| name     | alumno
|
| password |
$6$rounds=40000$8Q0MqKruQVZXvYZN$MeAsef3ihVpBWJrVUyBACF5TuiOwVSHtLU5HvkZBXrqXEmU0dvqjgNhfBc6eK6HZbatJ.CQDgQvkUNVrIBAjY1
|
| tenantId | e7b1868b24a742318f1d73f612ecfe1d
|
+----------+-------------------------------------------------------------------------------------------------------------------------+
<prompt>$</prompt><userinput> keystone user-list </userinput>
+----------------------------------+---------+--------------------+--------+
|                id                | enabled |       email        |  name  |
+----------------------------------+---------+--------------------+--------+
| 05743001bbf14700bcdf2ecc43edbf9b | True    | alex@iescierva.net | admin  |
| 246ba4e3d81c4ae8bdde8ec5784e74d3 | True    | alex@iescierva.net | swift  |
| 291c58f7258747758d109ecee2eb4a69 | True    | alex@iescierva.net | glance |
| 404dafc53b364a7e9f1476aa98082966 | True    | alex@iescierva.net | nova   |
| d0bfed18cce3460892ae99ee812d8aa3 | True    | correo@gmail.com   | alumno |
+----------------------------------+---------+--------------------+--------+
</screen>     
</listitem>
<listitem>
<para>Borrar un usuario sabiendo su id (ejemplo borrar usuario alumno)</para>
<screen><prompt>$</prompt><userinput> keystone user-delete d0bfed18cce3460892ae99ee812d8aa3 </userinput>
<prompt>$</prompt><userinput> keystone user-list</userinput></screen>
<screen>
+----------------------------------+---------+--------------------+--------+
|                id                | enabled |       email        |  name  |
+----------------------------------+---------+--------------------+--------+
| 05743001bbf14700bcdf2ecc43edbf9b | True    | alex@iescierva.net | admin  |
| 246ba4e3d81c4ae8bdde8ec5784e74d3 | True    | alex@iescierva.net | swift  |
| 291c58f7258747758d109ecee2eb4a69 | True    | alex@iescierva.net | glance |
| 404dafc53b364a7e9f1476aa98082966 | True    | alex@iescierva.net | nova   |
+----------------------------------+---------+--------------------+--------+
</screen>
</listitem>
<listitem>
<para>Obtener información detallada de un usuario</para>
<screen><prompt>$</prompt><userinput> keystone user-get 05743001bbf14700bcdf2ecc43edbf9b</userinput></screen>

<screen>
+----------+----------------------------------+
| Property |              Value               |
+----------+----------------------------------+
| email    | alex@iescierva.net               |
| enabled  | True                             |
| id       | 05743001bbf14700bcdf2ecc43edbf9b |
| name     | admin                            |
| tenantId | None                             |
+----------+----------------------------------+
</screen>
</listitem>
<listitem>
<para>Cambiar password de usuario</para>
<screen><prompt>$</prompt><userinput>keystone user-password-update --pass nuevopass 05743001bbf14700bcdf2ecc43edbf9b</userinput>
</screen>
</listitem>
</itemizedlist>
</section>

<section xml:id="id_admin_proyectos">
  <title>Gestión de proyectos </title>
<para>Al igual que con los usuarios la administración de proyectos se puede
realizar de forma gráfica a través de Horizon. Para realizarla en modo comando
se debe utilizar <emphasis role="bold">keystone.</emphasis>
</para>
<itemizedlist>
<listitem>
  <para>Listar proyectos (tenant)</para>
  <screen><prompt>$</prompt><userinput> keystone tenant-list</userinput>
+----------------------------------+---------+---------+
|                id                |   name  | enabled |
+----------------------------------+---------+---------+
| 634675c752634b53879656c81da70a83 | service | True    |
| e7b1868b24a742318f1d73f612ecfe1d | admin   | True    |
+----------------------------------+---------+---------+
  </screen>
</listitem>
<listitem>
  <para>Crear un proyecto</para>
<screen><prompt>$</prompt><userinput>keystone tenant-create --name asir1 --description "1 curso asir" </userinput>
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description | 1 curso asir                     |
| enabled     | True                             |
| id          | 8c6d42b3e339448fb3068ec512df7802 |
| name        | asir1                            |
+-------------+----------------------------------+
</screen>
</listitem>
<listitem>
<para>Listar información detallada de un proyecto</para>
<screen><prompt>$</prompt><userinput>keystone tenant-get 8c6d42b3e339448fb3068ec512df7802 </userinput></screen>

<screen>
+-------------+----------------------------------+
|   Property  |              Value               |
+-------------+----------------------------------+
| description | 1 curso asir                     |
| enabled     | True                             |
| id          | 8c6d42b3e339448fb3068ec512df7802 |
| name        | asir1                            |
+-------------+----------------------------------+
</screen>
</listitem>
<listitem>
<para>Borrar un proyecto</para>
<screen><prompt>$</prompt><userinput>keystone tenant-delete 8c6d42b3e339448fb3068ec512df7802</userinput>
</screen>           
</listitem>
</itemizedlist>

</section>

<section xml:id="id_gestion_roles">
<title>Gestión de roles y asignación a usuarios</title>
<para>A los usuarios una vez asignados de forma predeterminada a un
proyecto se les debe asignar uno o varios roles</para> 
<para>La gestión de los roles se realiza a través de <emphasis role="bold">keystone</emphasis>
</para>
<itemizedlist>
<listitem>
  <para><emphasis role="bold">Listar roles existentes</emphasis></para>
  <screen><prompt>$</prompt><userinput>keystone role-list</userinput></screen>
<screen>
+----------------------------------+--------+
|                id                |  name  |
+----------------------------------+--------+
| 2a716d669ce349eb88e44049723e0cb7 | admin  |
| 622c78f77bbe4a298452783f25cb4635 | Member |
+----------------------------------+--------+
  </screen>
  <para>Por defecto al instalar el sistema se crearon dos roles: <emphasis
  role="bold">admin</emphasis> y <emphasis role="bold">Member</emphasis>. 
</para>
</listitem>
<listitem>
  <para><emphasis role="bold">Asignación de rol a usuario</emphasis>
</para>
 <screen><prompt>$</prompt><userinput>keystone user-role-add
 --user=4ca77dc4d8a448219b1c6ae7a208ff47 --tenant=e7b1868b24a742318f1d73f612ecfe1d
 --role=622c78f77bbe4a298452783f25cb4635
</userinput>
</screen>
<para>Se le ha asignado el rol <emphasis role="bold">Member</emphasis>al usuario <emphasis role="bold">alumno</emphasis>
en el proyecto <emphasis role="bold">asir1</emphasis></para>
<para>Para verificarlo se puede ver con:</para>
<screen><prompt>$</prompt><userinput>keystone role-list
--user=4ca77dc4d8a448219b1c6ae7a208ff47
--tenant=e7b1868b24a742318f1d73f612ecfe1d</userinput></screen>
<screen>
+----------------------------------+--------+
|                id                |  name  |
+----------------------------------+--------+
| 622c78f77bbe4a298452783f25cb4635 | Member |
+----------------------------------+--------+
</screen>
</listitem>
<listitem>
  <para><emphasis role="bold">Desasignación de rol a usuario</emphasis></para>
<screen><prompt>$</prompt><userinput>keystone user-role-remove --user=4ca77dc4d8a448219b1c6ae7a208ff47
--tenant=e7b1868b24a742318f1d73f612ecfe1d
--role=622c78f77bbe4a298452783f25cb4635</userinput>
</screen>
<screen><prompt>$</prompt><userinput>keystone role-list
--user=4ca77dc4d8a448219b1c6ae7a208ff47
--tenant=e7b1868b24a742318f1d73f612ecfe1d</userinput></screen>
<screen>
+----+------+
| id | name |
+----+------+
+----+------+
</screen>
</listitem>
</itemizedlist>
</section>

<section xml:id="id_gestion_cuotas">
<title>Gestión de cuotas</title>
<para>La gestión de cuotas se realiza para cada proyecto concreto. Se pueden
fijar cuotas para parámetros como CPU's(cores), memoria, volúmenes,
instancias,numero de ip's, tamaño de disco, grupos de seguridad y ficheros
injectados(injected files)</para>
<para>Se puede realizar de forma gráfica con Horizon y de modo comando a través
de <emphasis role="bold">nova-manage</emphasis>
</para>
<itemizedlist>
<listitem>
  <para><emphasis role="bold">Obtener cuotas actuales de proyecto</emphasis></para>
<screen><prompt>$</prompt><userinput>nova-manage project quota
--project=e7b1868b24a742318f1d73f612ecfe1d</userinput></screen>
<screen>
metadata_items: 128
volumes: 10
gigabytes: 1000
ram: 51200
security_group_rules: 20
instances: 10
security_groups: 10
injected_file_content_bytes: 10240
floating_ips: 10
injected_files: 5
cores: 20
</screen>
</listitem>
<listitem>
 <para><emphasis role="bold">Modificar parámetro de cuota de
 proyecto (ej:ampliar num de cores a 50)</emphasis></para>
<screen><prompt>$</prompt><userinput>nova-manage project quota
--project=e7b1868b24a742318f1d73f612ecfe1d --key=cores --value=50</userinput>
metadata_items: 128
volumes: 40
gigabytes: 1000
ram: 51200
security_group_rules: 20
instances: 40
security_groups: 10
injected_file_content_bytes: 10240
floating_ips: 10
injected_files: 5
cores: 50
</screen>
</listitem>
</itemizedlist>
</section>

<section xml:id="id_monitor_nodos">
  <title>Monitorización de instancias y nodos</title>
  <para>La monitorización de instancias y nodos se puede realizar a través de comandos
    de <emphasis role="bold">nova</emphasis>.
 </para>
 <itemizedlist>
 <listitem>
   <para><emphasis role="bold">Listar instancias existentes en
   nova</emphasis></para>
   <screen><prompt>$</prompt><userinput>nova list</userinput></screen>
   <screen>
+--------------------------------------+---------------+--------+-------------------+
|                  ID                  |      Name     | Status |      Networks
|
+--------------------------------------+---------------+--------+-------------------+
| 0167eee1-9cbe-4bf2-a1b1-7d88b8259423 | UbuntuServer  | ACTIVE | private=10.0.0.17 |
| 0cf6b815-d7d5-4a0d-af3f-c45468eab6b5 | UbuntuServer1 | ACTIVE | private=10.0.0.9  |
| 11dada1d-90a5-46d5-b855-bbb447e48e65 | UbuntuServer2 | ACTIVE | private=10.0.0.30 |
| 1a8bba78-65fd-4ac5-96bb-8538d39f4825 | UbuntuServer3 | ACTIVE | private=10.0.0.32 |
| 1a8d14fb-39b1-4c9c-8501-fd81d0d59f01 | UbuntuServer4 | ACTIVE | private=10.0.0.21 |
| 32d9aa7c-3e94-4d73-afd8-f441ab7a00b7 | UbuntuServer5 | ACTIVE | private=10.0.0.24 |
| 3a4f4e81-48be-486a-82e8-ddec95aa6c40 | UbuntuServer6 | ACTIVE | private=10.0.0.22 |
-------------------------------------------------------------------------------------
   </screen>
 </listitem>
 <listitem>
 <para>Mostrar información de una instancia determinada</para>
 <screen><prompt>$</prompt><userinput>nova show
 0167eee1-9cbe-4bf2-a1b1-7d88b8259423</userinput></screen>
<screen>
+-------------------------------------+----------------------------------------------------------+
|               Property              |                          Value
|
+-------------------------------------+----------------------------------------------------------+
| OS-DCF:diskConfig                   | MANUAL
|
| OS-EXT-SRV-ATTR:host                | trinity
|
| OS-EXT-SRV-ATTR:hypervisor_hostname | None
|
| OS-EXT-SRV-ATTR:instance_name       | instance-0000004b
|
| OS-EXT-STS:power_state              | 1
|
| OS-EXT-STS:task_state               | None
|
| OS-EXT-STS:vm_state                 | active
|
| accessIPv4                          |
|
| accessIPv6                          |
|
| config_drive                        |
|
| created                             | 2012-09-24T09:06:40Z
|
| flavor                              | m1.medium
|
| hostId                              |
bcc6c02ce3eeaf89b869048bdf5039817b7c989be5e6ef7498dd09f9 |
| id                                  | 0167eee1-9cbe-4bf2-a1b1-7d88b8259423
|
| image                               | windows7plantilla
|
| key_name                            |
|
| metadata                            | {}
|
| name                                | UbuntuServer
|
| private network                     | 10.0.0.17
|
| progress                            | 0
|
| status                              | ACTIVE
|
| tenant_id                           | a70373bf297a42eb9203645d84476c23
|
| updated                             | 2012-09-24T09:06:38Z
|
| user_id                             | 4c249654613e41208b2d03169ef29580
|
+-------------------------------------+----------------------------------------------------------+
 </screen>
</listitem>
<listitem>
<para>Mostrar estado de los servicios de nova</para>
<screen><prompt>$</prompt><userinput>nova-manage service list</userinput></screen>

<screen>
Binary           Host                                 Zone             Status
State Updated_At
nova-cert        neo                                  nova             enabled :-)   2012-10-28 17:26:22
nova-network     neo                                  nova             enabled :-)   2012-10-28 17:26:22
nova-scheduler   neo                                  nova             enabled :-)   2012-10-28 17:26:22
nova-consoleauth neo                                  nova             enabled :-)   2012-10-28 17:26:22
nova-compute     trinity                              nova             enabled XXX   2012-10-28 17:25:11
nova-compute     cifra                                nova             enabled XXX   2012-09-28 15:12:00
nova-compute     tanque                               nova             enabled XXX   2012-09-28 15:12:27
nova-compute     dozer                                nova             enabled XXX   2012-09-28 15:12:50
</screen>
</listitem>
<listitem>
<para>Mostrar estado de recursos en un determinado nodo</para>
<screen><prompt>$</prompt><userinput>nova-manage service describe_resource trinity</userinput></screen>
<screen>
HOST                              PROJECT     cpu mem(mb)     hdd
trinity         (total)                        24   64414     824
trinity         (used_now)                     15    5995     101
trinity         (used_max)                     15   30720     300
trinity                  a70373bf297a42eb9203645d84476c23      15   30720 300
</screen>
</listitem>
</itemizedlist>
</section>
<section xml:id="id_servicios_vnc">
<title>Servicios VNC y VNCProxy</title>
<para><emphasis role="bold">VNC Proxy</emphasis></para>
<para>VNC Proxy es un componente de OpenStack que permite a los usuarios de los
servicios de Computación acceder a sus instancias a través clientes VNC. En Essex
y versiones posteriores viene soportado tanto por libvirt como por XenServer
utilizando tanto clientes Java como clientes de websocket.</para>
<para>La conexión VNC a través de consola funciona como sigue:</para>
<orderedlist>
<listitem>
  <para>El usuario se conecta a la API y recupera un acceso_url del tipo
  http://ip:port/?token=xyz</para>
</listitem>
<listitem>
<para>El usuario copia la URL en un navegador o como un parámetro de cliente</para>
</listitem>
<listitem>
  <para>El navegador o cliente se conecta al proxy</para>
</listitem>
<listitem>
  <para>El Proxy habla con nova-consoleauth para autorizar el token de usuario,
  entonces asocia el token al host privado y puerto de una instancia de VNC
  Server. En el nodo de computación se especifica la dirección que debe utilizar
  el proxy conectándose a través de la opción vncserver_proxy_client_address del
  fichero nova.conf. Así el vnc proxy trabaja como un puente entre la red
  pública y la red privada del host.</para>
</listitem>
<listitem>
  <para>El proxy inicia una conexión con VNC Server que durará hasta que la
  sesión finalice.</para>
</listitem>
</orderedlist>
<para>El proxy también puede realizar la función de tunelizar el protocolo VNC a
través de Websockets para que el cliente noVNC tenga una forma de hablar VNC. En
general VNC-proxy desarrolla varias funciones</para>

<itemizedlist>
  <listitem>
    <para>Puente entre la red pública (dónde están los clientes) y la red
    privada (dónde están los servidores VNC)</para>
  </listitem>
<listitem>
  <para>Facilita la authenticación vía token</para>
</listitem>
<listitem>
  <para>Provee una conexión uniforme con el hypervisor específico para
  homogeneizar la experiencia del usuario</para>
</listitem>
</itemizedlist>

<para><emphasis role="bold">Despliegue típico de VNC Proxy</emphasis></para>
<para>Un despliegue típico de VNC proxy consta de:</para>
<itemizedlist>
  <listitem>
    <para>Un proceso <emphasis
    role="bold">nova-consoleauth</emphasis>. Normalmente se instala en el nodo controlador.
    </para>
  </listitem>
<listitem>
  <para>Uno o varios servicios <emphasis
  role="bold">nova-novncproxy</emphasis>. Para dar soporte a los clientes novnc
  via navegador. En despliegues simples estos servicios pueden correr en el
  mismo host  que <emphasis role="bold">nova-api</emphasis>. Estos servicios
  actuan de proxies entre la red pública y la red privada de los hosts de computación.
</para>
</listitem>
<listitem>
  <para>Uno o varios servicios <emphasis
  role="bold">nova-xvpvncproxy</emphasis>. Estos servicios dan soporte a clientes
  Java especiales descritos más adelante. En despliegues simples estos servicios
  también pueden correr en el mismo host que <emphasis
  role="bold">nova-api</emphasis>. También actúan de proxies entre la red
  pública y la red privada de los hosts de computación.
 </para>
</listitem>
<listitem>
  <para>Uno o más hosts de computación. Estos hosts deberán tener correctamente
  configuradas las opciones para su correcto funcionamiento.</para>
</listitem>
</itemizedlist>
<para><emphasis role="bold">Obteniendo una URL de acceso</emphasis></para>
<para>Nova ofrece la posibilidad de crear URL's de acceso (access_urls) a través
de utilidades de consola</para>
<para>Se realiza a través de novaclient:</para>
<screen><prompt>$</prompt><userinput>nova get-vnc-console [server_id] [novnc|xvpnc]</userinput></screen>
<para>Si se especifíca "novnc" se obtiene una URL válida para utilizarla en un
navegador web. Por el contrario si se especifíca "xvpnc" se obtiene una URL para
utilizarla en un cliente Java.</para>
<para><emphasis role="bold">Opciones importantes de nova-compute</emphasis></para>
<para>Para activar vncproxy en el cloud, se tiene que tener instalado el
servicio de nova-consoleauth (normalmente en el controlador) y se deben
configurar las siguientes opciones en nova.conf en los nodos de
computación</para>

<itemizedlist>
  <listitem>
    <para>[no]vnc_enabled - Por defecto viene activado. Si se desactiva las
    instancias arrancaran sin soporte VNC.</para>
  </listitem>
<listitem>
  <para>vncserver_listen - Por defecto viene configurado a la 127.0.0.1. Es la
  dirección a la que se asocian los vncservers y podría ser cambiada en entornos
  de producción a una dirección privada. Se aplica solo a entornos libvirt. Para
  despliegues multi-host libvirt debería cambiarse por una dirección IP de gestión
  del nodo de computación. Dicha dirección IP estará en la misma red que los proxies</para>
</listitem>
<listitem>
  <para>vncserver_proxyclient_address - Por defecto viene configurado a la
  127.0.0.1. Esta es la dirección del nodo de computación que nova le pasa al
  proxy cuando se va a realizar una conexión a las instancias de
  vncservers. Para despliegues libvirt multi-host debe cambiarse por una
  dirección IP de gestión del nodo de computación. Dicha dirección IP estará en
  la misma red que los proxies.</para>
</listitem>
<listitem>
<para>novncproxy_base_url=[url base para los clientes] - Es la URL base a la que
los clientes se conectarán. A esta URL se le añadira "?token=abc" para propósito de
autenticación. Un despliegue típico tendrá la siguiente URL base
"http://$SERVICE_HOST:6080/vnc_auto.html" dónde SERVICE_HOST es el nombre
público del host</para>
</listitem>
<listitem>
  <para>xvpvncproxy_base_url=[url base para los clientes] - Es la URL base a la
  que los clientes se conectarán. A esta URL se le añadira "?token=abc" para
  propósito de autenticación. Un despliegue típico tendrá la siguiente URL base
  "http://$SERVICE_HOST:6081/console" dónde SERVICE_HOST es el nombre público
  del host.</para>
</listitem>
</itemizedlist>
<para> <emphasis role="bold">Acceso a consolas VNC desde cliente
Java</emphasis></para>
<para>Para activar el soporte de Openstack a los clientes Java se dispone del
servicios <emphasis role="bold">nova-xvpvncproxy</emphasis> que debe
configurarse como sigue:</para>
<itemizedlist>
  <listitem>
    <para>xvpvncproxy_port=[port] - puerto de escucha (por defecto 6081)</para>
  </listitem>
<listitem>
  <para>xvpvncproxy_host=[host] - ip del host (por defecto 0.0.0.0)</para>
</listitem>
</itemizedlist>
<para>Como cliente se necesita un cliente especial Java que es una versión
especial de TightVNC modificada para soportar los token de autenticación.</para>
<para>Para obtener ese cliente se puede hacer desde github</para>
<screen><prompt>$</prompt><userinput>git clone https://github.com/cloudbuilders/nova-xvpvncviewer</userinput>
<prompt>$</prompt><userinput>cd nova-xvpvncviewer</userinput>
<prompt>$</prompt><userinput>make</userinput></screen>

<para>Una vez que tengamos el cliente, para crear una conexión, debemos primero
obtener la URL de acceso a través de novaclient, como se ha comentado
anteriormente, y luego realizar la conexión a través del cliente</para>

<para>Para obtener la URL de acceso:</para>
<screen><prompt>$</prompt><userinput>nova get-vnc-console [server_id] xvpvnc</userinput></screen>

<para>Para realizar la conexión al host desde el cliente:</para>
<screen><prompt>$</prompt><userinput>java -jar VncViewer.jar [access_url]</userinput></screen>

<para><emphasis role="bold">Acceso VNC a través de navegador web</emphasis></para>
<para>Al igual que para el cliente Java, se debe obtener la URL de
acceso:</para>
<screen><prompt>$</prompt><userinput>nova get-vnc-console [server_id] novnc</userinput></screen>
<para> Una vez obtenida se le pasa al navegador web para realizar la conexión</para> 
</section>

</chapter>
